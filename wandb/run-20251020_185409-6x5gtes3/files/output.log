data loaded!
lr: 0.0001
Epoch 0/1000 | Avg Loss: 0.040992
Epoch 10/1000 | Avg Loss: 0.001531
Epoch 20/1000 | Avg Loss: 0.001220
Epoch 30/1000 | Avg Loss: 0.000869
Epoch 40/1000 | Avg Loss: 0.000686
Epoch 50/1000 | Avg Loss: 0.000597
Epoch 60/1000 | Avg Loss: 0.000492
Epoch 70/1000 | Avg Loss: 0.000417
Epoch 80/1000 | Avg Loss: 0.000383
Epoch 90/1000 | Avg Loss: 0.000381
Epoch 100/1000 | Avg Loss: 0.000399
Epoch 110/1000 | Avg Loss: 0.000413
Epoch 120/1000 | Avg Loss: 0.000386
Epoch 130/1000 | Avg Loss: 0.000345
Epoch 140/1000 | Avg Loss: 0.000309
Epoch 150/1000 | Avg Loss: 0.000325
Epoch 160/1000 | Avg Loss: 0.000276
Epoch 170/1000 | Avg Loss: 0.000345
Epoch 180/1000 | Avg Loss: 0.000251
Epoch 190/1000 | Avg Loss: 0.000288
Epoch 200/1000 | Avg Loss: 0.000278
Epoch 210/1000 | Avg Loss: 0.000303
Epoch 220/1000 | Avg Loss: 0.000289
Epoch 230/1000 | Avg Loss: 0.000237
Epoch 240/1000 | Avg Loss: 0.000328
Epoch 250/1000 | Avg Loss: 0.000369
Epoch 260/1000 | Avg Loss: 0.000292
Epoch 270/1000 | Avg Loss: 0.000284
Epoch 280/1000 | Avg Loss: 0.000323
Epoch 290/1000 | Avg Loss: 0.000263
Epoch 300/1000 | Avg Loss: 0.000257
Epoch 310/1000 | Avg Loss: 0.000285
Epoch 320/1000 | Avg Loss: 0.000295
Epoch 330/1000 | Avg Loss: 0.000298
Epoch 340/1000 | Avg Loss: 0.000330
Epoch 350/1000 | Avg Loss: 0.000236
Epoch 360/1000 | Avg Loss: 0.000290
Epoch 370/1000 | Avg Loss: 0.000288
Epoch 380/1000 | Avg Loss: 0.000290
Epoch 390/1000 | Avg Loss: 0.000323
Epoch 400/1000 | Avg Loss: 0.000215
Epoch 410/1000 | Avg Loss: 0.000298
Epoch 420/1000 | Avg Loss: 0.000252
Epoch 430/1000 | Avg Loss: 0.000280
Epoch 440/1000 | Avg Loss: 0.000315
Epoch 450/1000 | Avg Loss: 0.000319
Epoch 460/1000 | Avg Loss: 0.000232
Epoch 470/1000 | Avg Loss: 0.000278
Epoch 480/1000 | Avg Loss: 0.000204
Epoch 490/1000 | Avg Loss: 0.000235
Epoch 500/1000 | Avg Loss: 0.000250
Epoch 510/1000 | Avg Loss: 0.000274
Epoch 520/1000 | Avg Loss: 0.000235
Epoch 530/1000 | Avg Loss: 0.000271
Epoch 540/1000 | Avg Loss: 0.000254
Epoch 550/1000 | Avg Loss: 0.000163
Epoch 560/1000 | Avg Loss: 0.000233
Epoch 570/1000 | Avg Loss: 0.000233
Epoch 580/1000 | Avg Loss: 0.000232
Epoch 590/1000 | Avg Loss: 0.000213
Epoch 600/1000 | Avg Loss: 0.000174
Epoch 610/1000 | Avg Loss: 0.000263
Epoch 620/1000 | Avg Loss: 0.000187
Epoch 630/1000 | Avg Loss: 0.000189
Epoch 640/1000 | Avg Loss: 0.000254
Epoch 650/1000 | Avg Loss: 0.000242
Epoch 660/1000 | Avg Loss: 0.000195
Epoch 670/1000 | Avg Loss: 0.000229
Epoch 680/1000 | Avg Loss: 0.000225
Epoch 690/1000 | Avg Loss: 0.000184
Epoch 700/1000 | Avg Loss: 0.000173
Epoch 710/1000 | Avg Loss: 0.000210
Epoch 720/1000 | Avg Loss: 0.000211
Epoch 730/1000 | Avg Loss: 0.000163
Epoch 740/1000 | Avg Loss: 0.000287
Epoch 750/1000 | Avg Loss: 0.000159
Epoch 760/1000 | Avg Loss: 0.000141
Epoch 770/1000 | Avg Loss: 0.000203
Epoch 780/1000 | Avg Loss: 0.000178
Epoch 790/1000 | Avg Loss: 0.000137
Epoch 800/1000 | Avg Loss: 0.000168
Epoch 810/1000 | Avg Loss: 0.000203
Epoch 820/1000 | Avg Loss: 0.000164
Epoch 830/1000 | Avg Loss: 0.000145
Epoch 840/1000 | Avg Loss: 0.000205
Epoch 850/1000 | Avg Loss: 0.000206
Epoch 860/1000 | Avg Loss: 0.000204
Epoch 870/1000 | Avg Loss: 0.000203
Epoch 880/1000 | Avg Loss: 0.000160
Epoch 890/1000 | Avg Loss: 0.000128
Epoch 900/1000 | Avg Loss: 0.000163
Epoch 910/1000 | Avg Loss: 0.000185
Epoch 920/1000 | Avg Loss: 0.000177
Epoch 930/1000 | Avg Loss: 0.000155
Traceback (most recent call last):
  File "pixel.py", line 237, in <module>
    model = ReflectanceAutoEncoder(config).to(device)
  File "pixel.py", line 192, in train
    for batch in dataloader:
  File "pixel.py", line 174, in train_batch
    ref_gt, mask = batch[0].to(device), batch[1].to(device)
KeyboardInterrupt
